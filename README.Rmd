---
output: github_document
editor_options: 
  chunk_output_type: console
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# celavi

<!-- badges: start -->
[![R-CMD-check](https://github.com/jbkunst/celavi/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/jbkunst/celavi/actions/workflows/R-CMD-check.yaml)
<!-- badges: end -->

The goal of celavi is to join the main features of two functions  
that I use _really_ often `vip::vi_permute` and `DALEX::model_parts`. Both functions
do the _same_ task of calculate _drop out loss via permutation_, 
but they have different features and approach.

In the case of `vip::vi_permute` is more direct to use (imho), have an implementation for
parallel processing, can be used with a `sample_frac` parameter. Otherwise, in the case of `DALEX::model_parts` I like the user can give custom `metric`s as a loss functions,
the _base line_ and _full model_ references values, and the plots. 

To that features I added some features to my _personal_ taste.

- Add progress bars to the sequential and parallel process using `progress::progress_bar` and `progressr::progress`
- Give the possibility of to the user to access to the _raw_ data.
- Verbose information using `cli::cli_alert_info`.

## References

The `vip` package from [koalaverse](https://github.com/koalaverse), and the 
`DALEX` package from [MIÂ²](https://www.mi2.ai/). In particular these links are awesome: https://koalaverse.github.io/vip/articles/vip.html
and https://ema.drwhy.ai/featureImportance.html#featureImportanceR.

Please, visit the links and used that awesome tools!

## Installation

You can install the development version of celavi from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("jbkunst/celavi")
```

## Example I: Variable Importance

```{r example}
library(celavi)

lm_model <- lm(mpg ~ ., data = mtcars)

set.seed(123)

vi <- celavi::variable_importance(lm_model, data = mtcars, iterations = 10)

dplyr::glimpse(vi)

nrow(vi)
# nrow(vi) = (ncol(mtcars) - 1 + 2) * iterations

plot(vi)
```

And compare with other model.

```{r}
rf <- randomForest::randomForest(mpg ~ ., data = mtcars)

vi_rf <- celavi::variable_importance(rf, data = mtcars, iterations = 10)

plot(vi, vi_rf)
```

From the previous chart we can tell the random Forest have small (better) RMSE
and is less affected in terms of predictability by removing variables, wt variable
for example.

## Example II: Feature Selection

```{r}
set.seed(123)

data(credit_data, package = "modeldata")

credit_data <- credit_data[complete.cases(credit_data),]

fs <- feature_selection(
  # randomForest:::randomForest.formula,
  glm,
  credit_data,
  response = "Status",
  stat = min,
  iterations = 20,
  sample_frac = .5, 
  predict_function = predict.glm,
  # function accepts specific argument for the fit function
  family  = binomial,
  
)

fs

plot(fs)
```

We have a simpler model with 6 variables without loss significance predictive performance.

```{r}
do.call(plot, attr(fs, "variable_importance")) +
  ggplot2::scale_y_continuous(
    breaks = scales::pretty_breaks(7),
    sec.axis = ggplot2::dup_axis(~ 1 - .x, name = "AUC", labels = scales::percent)
  )

tail(fs$variables, 1)

step(glm(Status ~ ., data = credit_data, family = binomial), trace = FALSE, k = 100)
```




